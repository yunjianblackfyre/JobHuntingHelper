JobHuntingHelper
========
项目简述
========
 本项目旨在帮助海投简历求职者更轻松地投递职位。
 本项目编译完成的windows程序的主要工作流程：
 * 1.从多个求职网站上下载职位到本地。
 * 2.勾选合适的职位，一键批量投递。

方案思路
========
 * 1.现有招聘网站数量较多，可以利用特殊API驱动浏览器自动下载职位到本地，简化职位查询。
 * 2.为了继续改进职位查询的体验，可以利用算法提取关键词信息，简化职位浏览。
 * 3.为了进一步改进职位排序的体验，可以利用关键词信息进行职位相似度计算，减少发现合适职位的时间。
 * 4.同样利用特殊API驱动浏览器自动投递简历，可在多个招聘网站大量投递，减少用户重复劳动。
 
方案步骤
========
 * 1.用PyQt库开发windows桌面程序。
 * 2.用Selenium webdriver库与通用css配置，开发通用浏览器驱动API。
 * 3.用Scrapy通用爬虫框架爬取51智联20W职位作为关键词提取素材与LDA模型训练材料。
 * 4.用信息熵、word2vector、kmeans、jieba分词器、人工筛选的方式提取出职位关键词。
 * 5.用LDA主题模型计算文档向量，计算文档相似度实现排序。

方案资源
========
 * 操作系统：     Linux ubuntu 16.04.2 Windows 8.1
 * 开发语言：     python
 * 数据库：       mysql
 * 通用计算库     numpy
 * 爬虫：         scrapy
 * 分词器：       jieba
 * 主题模型：     gensim
 * 机器学习库：   sckit-learn
 * 浏览器驱动：   selenium webdriver
 * 图形界面程序： PyQt
    
方案细节
========
 * Scrapy框架爬取数据：
     * 其异步请求的特点保证了爬取的效率，可已在3小时内完成20W职位的爬取。
     * Scrapy经过本人进一步封装，使得解析与入库逻辑可配置，开发新爬虫的时间降低到半天左右。
 * 关键词提取方法：
     * 左右信息熵提取新词。
     * tfidf+分类信息熵第一轮过滤。
     * word2vector+kmeans+人工第二次过滤。
     * 排序测试--->人工第三次过滤
 * 文档相似度采用gensim的LDA主题模型方法：
     * 计算文档所属每个主题的概率。
     * 该概率序列构成文档向量，利用余弦距离计算文档相似度。
 * PyQt开发图形界面：
     * 基本的按键事件处理。
     * 运行于后台的线程用于与自动浏览器通信。
 * Selenium开发浏览器驱动API：
     * 开发职位下载器，利用通用配置批量抓取多源职位。
     * 开发简历投递器，利用通用配置批量投递多源职位。
